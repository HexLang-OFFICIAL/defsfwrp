<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>SmolLM 360M Chatbot with Fallback</title>
  <style>
    body {
      background: #121212;
      color: #eee;
      font-family: monospace;
      margin: 0; padding: 1rem;
      display: flex; flex-direction: column; height: 100vh;
    }
    #log {
      flex-grow: 1;
      background: #222;
      padding: 1rem;
      border-radius: 8px;
      overflow-y: auto;
      white-space: pre-wrap;
      margin-bottom: 1rem;
      border: 1px solid #555;
    }
    #input-container {
      display: flex; gap: 0.5rem;
    }
    input {
      flex-grow: 1;
      padding: 0.5rem;
      border-radius: 8px;
      border: none;
      font-size: 1rem;
      background: #333;
      color: #eee;
    }
    button {
      background: #7c52ff;
      border: none;
      border-radius: 8px;
      padding: 0 1rem;
      color: white;
      font-size: 1rem;
      cursor: pointer;
    }
    button:disabled {
      background: #555;
      cursor: not-allowed;
    }
  </style>
</head>
<body>

<h1>SmolLM 360M Chatbot with Fallback</h1>
<div id="log">Checking for WebGPU support...</div>

<div id="input-container">
  <input id="prompt" placeholder="Say something..." disabled autocomplete="off"/>
  <button id="sendBtn" disabled>Send</button>
</div>

<script type="module">
  import { pipeline, env } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.3.0/dist/transformers.min.js';

  const log = document.getElementById('log');
  const promptInput = document.getElementById('prompt');
  const sendBtn = document.getElementById('sendBtn');

  let generator;

  function appendLog(sender, text) {
    log.textContent += `\n${sender}: ${text}`;
    log.scrollTop = log.scrollHeight;
  }

  async function tryLoadModel() {
    try {
      // First, check if browser supports WebGPU
      if (navigator.gpu) {
        log.textContent = 'WebGPU supported. Loading model with WebGPU backend...';
        env.backends = ['webgpu', 'cpu']; // prioritize webgpu
      } else {
        log.textContent = 'WebGPU NOT supported. Falling back to CPU backend...';
        env.backends = ['cpu']; // fallback to CPU
      }

      generator = await pipeline('text-generation', 'HuggingFaceTB/SmolLM-360M-Instruct', {
        progress_callback(progress) {
          log.textContent = `Loading model... ${(progress * 100).toFixed(0)}%`;
        },
      });

      appendLog('System', 'Model loaded! You can chat now.');
      promptInput.disabled = false;
      sendBtn.disabled = false;
      promptInput.focus();
    } catch (e) {
      appendLog('System', `Failed to load model: ${e.message}`);
    }
  }

  async function sendMessage() {
    const text = promptInput.value.trim();
    if (!text) return;
    appendLog('You', text);
    promptInput.value = '';
    promptInput.disabled = true;
    sendBtn.disabled = true;

    try {
      const output = await generator(text, {
        max_new_tokens: 60,
        do_sample: true,
        temperature: 0.7,
        top_p: 0.9,
      });
      const response = output[0].generated_text.slice(text.length).trim();
      appendLog('AI', response || '[No response]');
    } catch (e) {
      appendLog('System', 'Error generating response: ' + e.message);
    } finally {
      promptInput.disabled = false;
      sendBtn.disabled = false;
      promptInput.focus();
    }
  }

  sendBtn.addEventListener('click', sendMessage);
  promptInput.addEventListener('keydown', e => {
    if (e.key === 'Enter' && !sendBtn.disabled) {
      sendMessage();
    }
  });

  tryLoadModel();
</script>

</body>
</html>
